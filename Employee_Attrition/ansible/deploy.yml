---
- name: Deploy Employee Attrition App Locally
  hosts: local
  connection: local
  gather_facts: false
  
  vars:
    kubeconfig: "{{ lookup('env', 'HOME') }}/.kube/config"
  
  tasks:
    - name: Delete previous resources
      ansible.builtin.shell: |
        kubectl --kubeconfig={{ kubeconfig }} delete hpa frontend-hpa backend-hpa -n employee-attrition --ignore-not-found=true
        kubectl --kubeconfig={{ kubeconfig }} delete service frontend-service backend-service -n employee-attrition --ignore-not-found=true
        kubectl --kubeconfig={{ kubeconfig }} delete deployment attrition-frontend attrition-backend -n employee-attrition --ignore-not-found=true
        kubectl --kubeconfig={{ kubeconfig }} delete configmap nginx-config -n employee-attrition --ignore-not-found=true
        kubectl --kubeconfig={{ kubeconfig }} delete pvc model-data-pvc app-logs-pvc -n employee-attrition --ignore-not-found=true
        # kubectl --kubeconfig={{ kubeconfig }} delete pv model-data-pv --ignore-not-found=true
      ignore_errors: yes
      
    - name: Apply namespace
      command: "kubectl --kubeconfig={{ kubeconfig }} apply -f ../k8s/namespace.yaml"
      
    - name: Apply persistent volume
      command: "kubectl --kubeconfig={{ kubeconfig }} apply -f ../k8s/persistent-volume.yaml -n employee-attrition"
      ignore_errors: true
    
    - name: Apply app logs persistent volume claim
      command: "kubectl --kubeconfig={{ kubeconfig }} apply -f ../k8s/app-logs-pvc.yaml -n employee-attrition"
      
    - name: Apply ConfigMap
      command: "kubectl --kubeconfig={{ kubeconfig }} apply -f ../k8s/nginx-configmap.yaml -n employee-attrition"
      
    - name: Deploy backend deployment
      command: "kubectl --kubeconfig={{ kubeconfig }} apply -f ../k8s/backend-deployment.yaml -n employee-attrition"
      
    - name: Deploy backend service
      command: "kubectl --kubeconfig={{ kubeconfig }} apply -f ../k8s/backend-service.yaml -n employee-attrition"
      
    - name: Deploy frontend deployment
      command: "kubectl --kubeconfig={{ kubeconfig }} apply -f ../k8s/frontend-deployment.yaml -n employee-attrition"
      
    - name: Deploy frontend service
      command: "kubectl --kubeconfig={{ kubeconfig }} apply -f ../k8s/frontend-service.yaml -n employee-attrition"
      
    - name: Apply backend HPA
      command: "kubectl --kubeconfig={{ kubeconfig }} apply -f ../k8s/backend-hpa.yaml -n employee-attrition"
      ignore_errors: true
      
    - name: Apply frontend HPA
      command: "kubectl --kubeconfig={{ kubeconfig }} apply -f ../k8s/frontend-hpa.yaml -n employee-attrition"
      ignore_errors: true
      
    - name: Wait for deployments to be ready
      command: "kubectl --kubeconfig={{ kubeconfig }} wait --for=condition=Available deployments --all -n employee-attrition --timeout=120s"
      ignore_errors: true
      
    - name: Get all resources
      command: "kubectl --kubeconfig={{ kubeconfig }} get all -n employee-attrition"
      register: resources
      
    - name: Display resources
      debug:
        var: resources.stdout_lines

    - name: Wait for backend deployment to be ready
      command: "kubectl --kubeconfig={{ kubeconfig }} wait --for=condition=Available deployment/attrition-backend -n employee-attrition --timeout=120s"
      ignore_errors: true

    - name: Run database migrations
      shell: |
        POD_NAME=$(kubectl --kubeconfig={{ kubeconfig }} get pods -n employee-attrition -l app=attrition-backend -o jsonpath='{.items[0].metadata.name}')
        kubectl --kubeconfig={{ kubeconfig }} exec -it $POD_NAME -n employee-attrition -- python manage.py migrate
      register: migration_output
      ignore_errors: true

    - name: Display migration output
      debug:
        var: migration_output.stdout_lines
      when: migration_output.stdout_lines is defined

    - name: Import data
      shell: |
        POD_NAME=$(kubectl --kubeconfig={{ kubeconfig }} get pods -n employee-attrition -l app=attrition-backend -o jsonpath='{.items[0].metadata.name}')
        kubectl --kubeconfig={{ kubeconfig }} exec -it $POD_NAME -n employee-attrition -- python manage.py runscript importdata
      register: import_output
      ignore_errors: true

    - name: Display import output
      debug:
        var: import_output.stdout_lines
      when: import_output.stdout_lines is defined

    - name: Apply ELK namespace
      command: "kubectl --kubeconfig={{ kubeconfig }} apply -f ../k8s/elk-namespace.yaml"
    
    - name: Clean up existing ELK stack deployments
      ansible.builtin.shell: |
        # Remove deployments first
        kubectl --kubeconfig={{ kubeconfig }} delete deployment elasticsearch logstash kibana -n elk-monitoring --ignore-not-found=true
        kubectl --kubeconfig={{ kubeconfig }} delete daemonset filebeat metricbeat -n elk-monitoring --ignore-not-found=true
        
        # Remove services
        kubectl --kubeconfig={{ kubeconfig }} delete service elasticsearch logstash kibana -n elk-monitoring --ignore-not-found=true
        
        # Remove configmaps
        kubectl --kubeconfig={{ kubeconfig }} delete configmap logstash-config filebeat-config metricbeat-config -n elk-monitoring --ignore-not-found=true
        
        # Remove PVCs (last, after deployments are gone)
        kubectl --kubeconfig={{ kubeconfig }} delete pvc elasticsearch-data-pvc -n elk-monitoring --ignore-not-found=true
        
        # Remove service accounts and roles
        kubectl --kubeconfig={{ kubeconfig }} delete serviceaccount filebeat metricbeat -n elk-monitoring --ignore-not-found=true
        kubectl --kubeconfig={{ kubeconfig }} delete clusterrole filebeat metricbeat --ignore-not-found=true
        kubectl --kubeconfig={{ kubeconfig }} delete clusterrolebinding filebeat metricbeat --ignore-not-found=true
        
        # Wait for resources to be removed
        sleep 5
      ignore_errors: yes
      
    - name: Apply Elasticsearch persistent volume
      command: "kubectl --kubeconfig={{ kubeconfig }} apply -f ../k8s/elasticsearch-storage.yaml"
      
    - name: Wait for PVC to be bound
      command: "kubectl --kubeconfig={{ kubeconfig }} wait --for=condition=bound pvc/elasticsearch-data-pvc -n elk-monitoring --timeout=30s"
      ignore_errors: true
      
    - name: Deploy Elasticsearch
      command: "kubectl --kubeconfig={{ kubeconfig }} apply -f ../k8s/elasticsearch.yaml"
      
    - name: Deploy Logstash
      command: "kubectl --kubeconfig={{ kubeconfig }} apply -f ../k8s/logstash.yaml"
      
    - name: Deploy Kibana
      command: "kubectl --kubeconfig={{ kubeconfig }} apply -f ../k8s/kibana.yaml"
      
    - name: Deploy Filebeat
      command: "kubectl --kubeconfig={{ kubeconfig }} apply -f ../k8s/filebeat.yaml"
      
    - name: Deploy Metricbeat for system metrics
      command: "kubectl --kubeconfig={{ kubeconfig }} apply -f ../k8s/metricbeat.yaml"
      
    - name: Wait for ELK stack to be ready
      command: "kubectl --kubeconfig={{ kubeconfig }} wait --for=condition=Available deployments --all -n elk-monitoring --timeout=180s"
      ignore_errors: true
      
    - name: Get ELK resources
      command: "kubectl --kubeconfig={{ kubeconfig }} get all -n elk-monitoring"
      register: elk_resources
      
    - name: Display ELK resources
      debug:
        var: elk_resources.stdout_lines
